"""
Generate narrative explanations for V12 scores using Gemini.

This script:
  1. Loads the SHAP detail CSV generated by `v12_shap_analysis.py`.
  2. Assigns each lead to a percentile bucket (Top 10%, Top 25%, Top 50%, Lower 50%).
  3. Extracts top positive/negative SHAP contributors and translates them into readable phrases.
  4. Calls Gemini to produce a short narrative justification for the lead's bucket placement.
  5. Writes the enriched dataset (including the narrative) back to CSV and optionally BigQuery.

Usage example:
--------------
python v12_generate_narratives.py \
    --shap-detail C:/Users/russe/Documents/Lead Scoring/v12_shap_detail.csv \
    --scores-csv C:/Users/russe/Documents/Lead Scoring/impact_attendees_v12_scores.csv \
    --output-csv C:/Users/russe/Documents/Lead Scoring/impact_attendees_v12_scores_with_narratives.csv \
    --project savvy-gtm-analytics \
    --output-bq-table savvy-gtm-analytics.LeadScoring.Impact_Attendees_V12_Scores_Explained \
    --model gemini-1.5-pro
"""

from __future__ import annotations

import argparse
import json
import os
from collections import defaultdict
from pathlib import Path
from typing import Dict, Iterable, List, Tuple

import numpy as np
import pandas as pd
import google.generativeai as genai
from google.cloud import bigquery
from tqdm import tqdm

try:
    from dotenv import load_dotenv
    load_dotenv()
except Exception:
    pass


DEFAULT_SHAP_DETAIL = Path("C:/Users/russe/Documents/Lead Scoring/v12_shap_detail.csv")
DEFAULT_SCORES_CSV = Path("C:/Users/russe/Documents/Lead Scoring/impact_attendees_v12_scores.csv")
DEFAULT_OUTPUT_CSV = Path("C:/Users/russe/Documents/Lead Scoring/impact_attendees_v12_scores_with_narratives.csv")


FEATURE_DESCRIPTIONS: Dict[str, str] = {
    "Firm_Stability_Score_v12_binned_Low_Under_30": "Low firm stability (frequent moves recently)",
    "Firm_Stability_Score_v12_binned_Moderate_30_to_60": "Moderate firm stability (some movement)",
    "Firm_Stability_Score_v12_binned_High_60_to_90": "High firm stability (tends to stay put)",
    "Firm_Stability_Score_v12_binned_Very_High_90_Plus": "Very high firm stability (long tenure at current firm)",
    "Firm_Stability_Score_v12_binned_Missing_Zero": "Firm stability information missing",
    "AverageTenureAtPriorFirms_binned_Short_Under_2": "Short average tenure at prior firms (<2 years)",
    "AverageTenureAtPriorFirms_binned_Moderate_2_to_5": "Moderate average tenure (2-5 years) at prior firms",
    "AverageTenureAtPriorFirms_binned_Long_5_to_10": "Longer average tenure (5-10 years) at prior firms",
    "AverageTenureAtPriorFirms_binned_Very_Long_10_Plus": "Very long tenure (10+ years) at prior firms",
    "AverageTenureAtPriorFirms_binned_No_Prior_Firms": "No prior firm history",
    "Number_YearsPriorFirm1_binned_Short_Under_3": "Stayed less than 3 years at most recent prior firm",
    "Number_YearsPriorFirm1_binned_Moderate_3_to_7": "Stayed 3-7 years at most recent prior firm",
    "Number_YearsPriorFirm1_binned_Long_7_Plus": "Stayed 7+ years at most recent prior firm",
    "Number_YearsPriorFirm1_binned_No_Prior_Firm_1": "No prior firm 1 history",
    "Gender_Male": "Gender recorded as male",
    "Gender_Missing": "Gender information missing or not specified",
    "RegulatoryDisclosures_Yes": "Regulatory disclosures on file",
    "RegulatoryDisclosures_Unknown": "Regulatory disclosures missing",
}


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Generate narrative explanations for V12 scores using Gemini.")
    parser.add_argument("--shap-detail", default=str(DEFAULT_SHAP_DETAIL), help="Path to SHAP detail CSV.")
    parser.add_argument("--scores-csv", default=str(DEFAULT_SCORES_CSV), help="Path to scored leads CSV.")
    parser.add_argument("--output-csv", default=str(DEFAULT_OUTPUT_CSV), help="Path for enriched CSV output.")
    parser.add_argument("--project", default=None, help="BigQuery project for optional write-back.")
    parser.add_argument("--output-bq-table", default=None, help="Destination BigQuery table for enriched dataset.")
    parser.add_argument("--model", default="models/gemini-2.5-flash", help="Gemini model name to use.")
    parser.add_argument("--top-shap-count", type=int, default=3, help="Number of top positive/negative SHAP drivers to include.")
    parser.add_argument("--batch-size", type=int, default=20, help="Number of leads to send per Gemini request.")
    parser.add_argument("--max-leads", type=int, default=None, help="Optional cap on number of leads to process.")
    parser.add_argument("--bucket-percentiles", nargs=3, type=float, default=[0.9, 0.75, 0.5],
                        help="Percentiles to define top10/top25/top50 buckets (values between 0 and 1).")
    parser.add_argument("--recent-move-threshold", type=float, default=1.0,
                        help="Maximum years at current firm to flag a recent move (default: 1 year).")
    parser.add_argument("--api-key-env", default="GEMINI_API_KEY", help="Environment variable containing Gemini API key.")
    return parser.parse_args()


MODEL_ALIASES = {
    "gemini-1.5-pro": "models/gemini-pro-latest",
    "gemini-1.5-flash": "models/gemini-flash-latest",
    "gemini-1.5-pro-latest": "models/gemini-pro-latest",
    "gemini-1.5-flash-latest": "models/gemini-flash-latest",
    "gemini-pro": "models/gemini-pro-latest",
    "gemini-flash": "models/gemini-flash-latest",
    "gemini-pro-latest": "models/gemini-pro-latest",
    "gemini-flash-latest": "models/gemini-flash-latest",
}


def configure_gemini(api_key: str, model_name: str):
    if not api_key:
        raise ValueError("Gemini API key not found. Set the environment variable and retry.")
    resolved_name = MODEL_ALIASES.get(model_name, model_name)
    if not resolved_name.startswith("models/"):
        resolved_name = f"models/{resolved_name}"
    genai.configure(api_key=api_key)
    return genai.GenerativeModel(resolved_name)


def assign_buckets(scores: pd.Series, percentiles: Iterable[float]) -> Tuple[pd.Series, Dict[str, float]]:
    p90, p75, p50 = percentiles
    thresholds = {
        "top_10_threshold": scores.quantile(p90),
        "top_25_threshold": scores.quantile(p75),
        "top_50_threshold": scores.quantile(p50),
    }

    def label(score: float) -> str:
        if score >= thresholds["top_10_threshold"]:
            return "Top 10%"
        if score >= thresholds["top_25_threshold"]:
            return "Top 25%"
        if score >= thresholds["top_50_threshold"]:
            return "Top 50%"
        return "Lower 50%"

    return scores.apply(label), thresholds


def extract_shap_drivers(row: pd.Series, shap_cols: List[str], top_n: int) -> Tuple[List[Tuple[str, float]], List[Tuple[str, float]]]:
    shap_vals = {col[len("shap_"):]: row[col] for col in shap_cols}
    positives = sorted([(feat, val) for feat, val in shap_vals.items() if val > 0], key=lambda x: x[1], reverse=True)[:top_n]
    negatives = sorted([(feat, val) for feat, val in shap_vals.items() if val < 0], key=lambda x: x[1])[:top_n]
    return positives, negatives


def describe_feature(feature: str) -> str:
    return FEATURE_DESCRIPTIONS.get(feature, feature.replace("_", " "))


def format_drivers(drivers: List[Tuple[str, float]]) -> List[str]:
    formatted = []
    for feat, val in drivers:
        description = describe_feature(feat)
        formatted.append(f"{description} (SHAP {val:+.3f})")
    return formatted


def build_prompt(
    row: pd.Series,
    bucket: str,
    positives: List[str],
    negatives: List[str],
) -> str:
    lead_name = f"{row.get('Impact_FirstName', '').strip()} {row.get('Impact_LastName', '').strip()}".strip()
    if not lead_name:
        lead_name = f"Rep {row.get('RepCRD', 'Unknown')}"

    v12_score = row.get("v12_score", np.nan)

    prompt = [
        "You are a sales strategist generating a short, plain-language justification for why a financial advisor lead is prioritized at a certain tier.",
        "Keep the tone professional but conversational, and limit the explanation to 2-3 sentences.",
        "Highlight the most important positive drivers when the lead is in a top bucket; mention cautionary factors for lower buckets.",
        "If the recent_move_flag is true, explicitly explain that the rep recently moved firms (include the provided hire date if present) and that their score was suppressed because they are unlikely to change firms again soon.",
        "",
        f"Lead: {lead_name}",
        f"RepCRD: {row.get('RepCRD', 'N/A')}",
        f"Percentile bucket: {bucket}",
        f"V12 score: {v12_score:.3f}" if not pd.isna(v12_score) else "V12 score: N/A",
        f"Recent move flag: {row.get('recent_move_flag', False)}",
    ]

    recent_move_date = row.get("recent_move_hire_date")
    if recent_move_date:
        prompt.append(f"Recent move hire date: {recent_move_date}")

    if positives:
        prompt.append("\nPositive drivers:")
        prompt.extend(f"- {driver}" for driver in positives)
    if negatives:
        prompt.append("\nLower-weight drivers or caution flags:")
        prompt.extend(f"- {driver}" for driver in negatives)

    prompt.append(
        "\nWrite an explanation tailored to the bucket. For Top 10/25/50 buckets, emphasize why the lead is attractive. For the lower 50%, explain why they are deprioritized."
    )

    return "\n".join(prompt)


def parse_gemini_json(text: str, expected: int) -> List[Dict[str, str]]:
    cleaned = text.strip()
    if cleaned.startswith("```"):
        parts = cleaned.split("```")
        cleaned = ""
        for part in parts:
            part = part.strip()
            if not part:
                continue
            if part.lower().startswith("json"):
                part = part[4:].strip()
            if part:
                cleaned = part
                break
    try:
        data = json.loads(cleaned)
        if isinstance(data, dict) and "items" in data:
            data = data["items"]
        if isinstance(data, dict) and "results" in data:
            data = data["results"]
        if not isinstance(data, list):
            raise ValueError("Response is not a list")
        if len(data) != expected:
            raise ValueError(f"Expected {expected} items, got {len(data)}")
        return data
    except Exception as exc:
        raise ValueError(f"Failed to parse Gemini response: {exc}\nRaw response: {text}") from exc


def generate_narratives(
    model,
    df: pd.DataFrame,
    bucket_labels: pd.Series,
    shap_cols: List[str],
    top_n: int,
    batch_size: int,
) -> List[str]:
    narratives: List[str] = []
    total = len(df)
    iterator = range(0, total, batch_size)
    for start in tqdm(iterator, desc="Generating narratives", total=(total + batch_size - 1) // batch_size):
        end = min(start + batch_size, total)
        batch_df = df.iloc[start:end]
        prompt_lines = [
            "You are a sales strategist. For each lead below, write a concise 2-3 sentence narrative explaining why they fall into the specified priority bucket.",
            "Use the provided positive drivers as the main reasons. Mention cautionary factors only if negative drivers are present.",
            "Return ONLY a JSON array. Each element must have keys 'rep_crd' and 'narrative'. The order must match the inputs.",
        ]

        for idx, (_, row) in enumerate(batch_df.iterrows(), start=1):
            bucket = bucket_labels.loc[row.name]
            positives_raw, negatives_raw = extract_shap_drivers(row, shap_cols, top_n)
            positives = format_drivers(positives_raw)
            negatives = format_drivers(negatives_raw)
            entry = {
                "rep_crd": str(row.get("RepCRD", "")),
                "bucket": bucket,
                "score": float(row.get("v12_score", 0)),
                "positives": positives,
                "negatives": negatives,
                "recent_move": bool(row.get("recent_move_flag", False)),
                "recent_move_hire_date": row.get("recent_move_hire_date"),
            }
            prompt_lines.append(f"{idx}. {json.dumps(entry)}")

        prompt_lines.append(
            "Respond with a JSON array matching the order of the inputs. Each element must include keys 'rep_crd' and 'narrative'. If recent_move is true, mention the recent move and the lowered likelihood of another move soon."
        )
        prompt = "\n".join(prompt_lines)

        try:
            response = model.generate_content(prompt)
            batch_results = parse_gemini_json(response.text, len(batch_df))
            rep_to_text = {str(item.get("rep_crd", "")): item.get("narrative", "").strip() for item in batch_results}
            for _, row in batch_df.iterrows():
                rep_key = str(row.get("RepCRD", ""))
                narratives.append(rep_to_text.get(rep_key, "[ERROR] Narrative missing from Gemini response"))
        except Exception as exc:
            for _ in batch_df.iterrows():
                narratives.append(f"[ERROR] Unable to generate narrative: {exc}")

    return narratives


def write_to_bigquery(df: pd.DataFrame, table_id: str, project: str | None) -> None:
    if not project:
        raise ValueError("Project must be provided to write to BigQuery.")
    client = bigquery.Client(project=project)
    job = client.load_table_from_dataframe(df, table_id, job_config=bigquery.LoadJobConfig(write_disposition="WRITE_TRUNCATE"))
    job.result()
    print(f"[OK] Narratives written to BigQuery: {table_id}")


def main() -> None:
    args = parse_args()

    shap_df = pd.read_csv(args.shap_detail)
    scores_df = pd.read_csv(args.scores_csv)

    merged_df = shap_df.merge(scores_df, on="RepCRD", suffixes=("_shap", "_score"))

    recent_move_columns = [
        "tgt_DateOfHireAtCurrentFirm_NumberOfYears",
        "DateOfHireAtCurrentFirm_NumberOfYears",
    ]
    hire_date_columns = [
        "tgt_DateOfHireAtCurrentFirm_Full",
        "DateOfHireAtCurrentFirm_Full",
    ]

    recent_move_years = None
    for col in recent_move_columns:
        if col in merged_df.columns:
            recent_move_years = merged_df[col]
            break
    if recent_move_years is not None:
        merged_df["recent_move_flag"] = recent_move_years.fillna(np.inf) <= args.recent_move_threshold
    else:
        merged_df["recent_move_flag"] = False

    recent_hire_date = None
    for col in hire_date_columns:
        if col in merged_df.columns:
            recent_hire_date = merged_df[col]
            break
    if recent_hire_date is not None:
        merged_df["recent_move_hire_date"] = recent_hire_date
    else:
        merged_df["recent_move_hire_date"] = ""

    if args.max_leads:
        merged_df = merged_df.head(args.max_leads)

    bucket_labels, thresholds = assign_buckets(merged_df["v12_score"], args.bucket_percentiles)
    merged_df["bucket"] = bucket_labels

    shap_cols = [col for col in merged_df.columns if col.startswith("shap_")]

    api_key = os.getenv(args.api_key_env)
    model = configure_gemini(api_key, args.model)

    narratives = generate_narratives(
        model,
        merged_df,
        bucket_labels,
        shap_cols,
        args.top_shap_count,
        args.batch_size,
    )
    merged_df["v12_narrative"] = narratives

    base_columns = [col for col in scores_df.columns if not col.startswith("v12_")]
    final_df = pd.DataFrame(index=merged_df.index)
    for col in base_columns:
        if col in merged_df.columns:
            final_df[col] = merged_df[col]
        elif f"{col}_score" in merged_df.columns:
            final_df[col] = merged_df[f"{col}_score"]
        else:
            final_df[col] = np.nan
    final_df["v12_score"] = merged_df["v12_score"]
    final_df["v12_narrative"] = merged_df["v12_narrative"]
    final_df["recent_move_flag"] = merged_df["recent_move_flag"].astype(bool)
    final_df["recent_move_hire_date"] = merged_df["recent_move_hire_date"]

    output_path = Path(args.output_csv)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    final_df.to_csv(output_path, index=False)
    print(f"[OK] Enriched CSV saved: {output_path}")

    if args.output_bq_table:
        write_to_bigquery(final_df, args.output_bq_table, args.project)

    print("[INFO] Bucket thresholds (scores):")
    for key, value in thresholds.items():
        print(f"  {key}: {value:.4f}")


if __name__ == "__main__":
    main()


