"""
V9 Lead Scoring Model - Hybrid Intelligence Approach

Combines m5's proven features with smart engineering and ensemble methods
Target: 10-12% AUC-PR
"""

import pandas as pd
import numpy as np
from google.cloud import bigquery
from datetime import datetime
import warnings
import pickle
import json
import os
from pathlib import Path
from sklearn.model_selection import TimeSeriesSplit
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_auc_score, average_precision_score
from sklearn.feature_selection import SelectFromModel
from imblearn.over_sampling import SMOTE, ADASYN
from imblearn.combine import SMOTETomek
import xgboost as xgb

warnings.filterwarnings('ignore')

# Configuration
PROJECT = 'savvy-gtm-analytics'
DATASET = 'LeadScoring'
V7_TABLE = 'step_3_3_training_dataset_v7_featured_20251105'

# Get script directory for output
script_dir = Path(__file__).parent.absolute()
OUTPUT_DIR = script_dir
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# Initialize BigQuery client
client = bigquery.Client(project=PROJECT)

print("="*60)
print("V9 LEAD SCORING MODEL - HYBRID INTELLIGENCE")
print("="*60)
print(f"Start Time: {datetime.now()}")
print(f"Output Directory: {OUTPUT_DIR}")
print("="*60)

# ========================================
# STEP 1: ADVANCED DATA EXTRACTION
# ========================================

print("\n[STEP 1] ADVANCED DATA EXTRACTION")
print("-"*40)

# Enhanced query with better feature engineering
sql_extract_v9 = f"""
WITH cleaned_base AS (
    SELECT 
        -- Core identifiers
        Id,
        FA_CRD__c,
        target_label,
        Stage_Entered_Contacting__c,
        
        -- Clean financial features (same as V8)
        CASE 
            WHEN TotalAssetsInMillions > 5000 THEN 5000
            WHEN TotalAssetsInMillions < 0 THEN 0
            WHEN TotalAssetsInMillions IS NULL THEN 0
            ELSE TotalAssetsInMillions
        END as AUM,
        
        CASE 
            WHEN NumberClients_Individuals > 5000 THEN 5000
            WHEN NumberClients_Individuals < 0 THEN 0
            WHEN NumberClients_Individuals IS NULL THEN 0
            ELSE NumberClients_Individuals
        END as ClientCount,
        
        CASE 
            WHEN AUMGrowthRate_1Year > 5 THEN 5
            WHEN AUMGrowthRate_1Year < -0.9 THEN -0.9
            WHEN AUMGrowthRate_1Year IS NULL THEN 0
            ELSE AUMGrowthRate_1Year
        END as GrowthRate,
        
        -- All base features
        DateBecameRep_NumberOfYears,
        DateOfHireAtCurrentFirm_NumberOfYears,
        NumberFirmAssociations,
        NumberRIAFirmAssociations,
        Number_IAReps,
        Number_BranchAdvisors,
        
        -- All licenses
        CAST(Has_Series_7 AS INT64) as Has_Series_7,
        CAST(Has_Series_65 AS INT64) as Has_Series_65,
        CAST(Has_Series_66 AS INT64) as Has_Series_66,
        CAST(Has_Series_24 AS INT64) as Has_Series_24,
        CAST(Has_CFP AS INT64) as Has_CFP,
        CAST(Has_CFA AS INT64) as Has_CFA,
        CAST(Has_CIMA AS INT64) as Has_CIMA,
        CAST(Has_AIF AS INT64) as Has_AIF,
        
        -- Professional characteristics
        CAST(Is_BreakawayRep AS INT64) as Is_BreakawayRep,
        CAST(Is_Owner AS INT64) as Is_Owner,
        CAST(Is_IndependentContractor AS INT64) as Is_IndependentContractor,
        CAST(Is_NonProducer AS INT64) as Is_NonProducer,
        
        -- Geographic
        Home_State,
        Branch_State,
        Number_RegisteredStates,
        
        -- Digital presence
        CASE WHEN SocialMedia_LinkedIn IS NOT NULL THEN 1 ELSE 0 END as Has_LinkedIn,
        
        -- Client composition (all cleaned)
        CASE 
            WHEN PercentClients_HNWIndividuals > 1 THEN 1
            WHEN PercentClients_HNWIndividuals < 0 THEN 0
            WHEN PercentClients_HNWIndividuals IS NULL THEN 0
            ELSE PercentClients_HNWIndividuals
        END as Pct_HNW,
        
        CASE 
            WHEN PercentClients_Individuals > 1 THEN 1
            WHEN PercentClients_Individuals < 0 THEN 0
            WHEN PercentClients_Individuals IS NULL THEN 0
            ELSE PercentClients_Individuals
        END as Pct_Individual,
        
        -- Asset composition
        CASE 
            WHEN PercentAssets_MutualFunds > 1 THEN 1
            WHEN PercentAssets_MutualFunds < 0 THEN 0
            WHEN PercentAssets_MutualFunds IS NULL THEN 0
            ELSE PercentAssets_MutualFunds
        END as Pct_MutualFunds,
        
        CASE 
            WHEN PercentAssets_PrivateFunds > 1 THEN 1
            WHEN PercentAssets_PrivateFunds < 0 THEN 0
            WHEN PercentAssets_PrivateFunds IS NULL THEN 0
            ELSE PercentAssets_PrivateFunds
        END as Pct_PrivateFunds,
        
        CASE 
            WHEN PercentAssets_Equity_ExchangeTraded > 1 THEN 1
            WHEN PercentAssets_Equity_ExchangeTraded < 0 THEN 0
            WHEN PercentAssets_Equity_ExchangeTraded IS NULL THEN 0
            ELSE PercentAssets_Equity_ExchangeTraded
        END as Pct_ETF,
        
        -- Additional raw features for engineering
        AssetsInMillions_HNWIndividuals,
        AssetsInMillions_Individuals,
        NumberClients_HNWIndividuals,
        NumberClients_RetirementPlans,
        AverageTenureAtPriorFirms,
        NumberOfPriorFirms,
        
        -- Firm features
        total_reps,
        total_firm_aum_millions,
        
        -- Custodian relationships
        CAST(Has_Schwab_Relationship AS INT64) as Has_Schwab,
        CAST(Has_Fidelity_Relationship AS INT64) as Has_Fidelity,
        CAST(Has_Pershing_Relationship AS INT64) as Has_Pershing,
        CAST(Has_TDAmeritrade_Relationship AS INT64) as Has_TD
        
    FROM 
        `{PROJECT}.{DATASET}.{V7_TABLE}`
    WHERE
        -- Basic data quality filters
        FA_CRD__c IS NOT NULL
        AND (TotalAssetsInMillions IS NULL OR TotalAssetsInMillions < 1000000)
        AND (NumberClients_Individuals IS NULL OR NumberClients_Individuals < 100000)
),
engineered AS (
    SELECT 
        *,
        
        -- === M5'S TOP PROVEN FEATURES (MUST INCLUDE) ===
        
        -- 1. Multi RIA Relationships (m5's #1)
        CASE WHEN NumberRIAFirmAssociations > 1 THEN 1 ELSE 0 END as Multi_RIA,
        
        -- 2. HNW Concentration
        CASE 
            WHEN AUM > 0 AND AssetsInMillions_HNWIndividuals IS NOT NULL AND AssetsInMillions_HNWIndividuals > 0
            THEN SAFE_DIVIDE(AssetsInMillions_HNWIndividuals, AUM)
            ELSE 0
        END as HNW_Concentration,
        
        -- 3. AUM per Client
        CASE 
            WHEN ClientCount > 0 THEN SAFE_DIVIDE(AUM, ClientCount)
            ELSE 0
        END as AUM_per_Client,
        
        -- 4. Growth Momentum
        CASE WHEN GrowthRate > 0.15 THEN 1 ELSE 0 END as Growth_Momentum,
        
        -- 5. Firm Stability Score
        CASE 
            WHEN DateOfHireAtCurrentFirm_NumberOfYears > 0 AND DateBecameRep_NumberOfYears > 0
            THEN SAFE_DIVIDE(DateOfHireAtCurrentFirm_NumberOfYears, DateBecameRep_NumberOfYears)
            ELSE 0
        END as Firm_Stability,
        
        -- === NEW ENGINEERED FEATURES FOR V9 ===
        
        -- Experience Features
        CASE 
            WHEN DateBecameRep_NumberOfYears < 3 THEN 'New'
            WHEN DateBecameRep_NumberOfYears < 7 THEN 'Growing'
            WHEN DateBecameRep_NumberOfYears < 15 THEN 'Established'
            ELSE 'Veteran'
        END as Career_Stage,
        
        -- AUM Tiers
        CASE 
            WHEN AUM < 50 THEN 'Small'
            WHEN AUM < 250 THEN 'Medium'
            WHEN AUM < 1000 THEN 'Large'
            ELSE 'Mega'
        END as AUM_Tier,
        
        -- Client Sophistication
        CASE 
            WHEN Pct_HNW > 0.5 THEN 'HNW_Focus'
            WHEN Pct_Individual > 0.8 THEN 'Mass_Affluent'
            WHEN Pct_PrivateFunds > 0.2 THEN 'Institutional'
            ELSE 'Mixed'
        END as Client_Type,
        
        -- License Sophistication Score
        Has_Series_7 + Has_Series_65 + Has_Series_66 + Has_Series_24 as License_Score,
        
        -- Designation Quality Score
        Has_CFP*2 + Has_CFA*3 + Has_CIMA*2 + Has_AIF as Designation_Score,
        
        -- Digital Sophistication
        Has_LinkedIn as Digital_Score,
        
        -- Independence Indicator
        Is_IndependentContractor + Is_Owner as Independence_Score,
        
        -- Custodian Diversity
        Has_Schwab + Has_Fidelity + Has_Pershing + Has_TD as Custodian_Count,
        
        -- === INTERACTION FEATURES ===
        
        -- High value combinations
        Has_CFP * (CASE WHEN AUM > 100 THEN 1 ELSE 0 END) as CFP_HighAUM,
        Has_Series_65 * Is_IndependentContractor as Independent_65,
        Is_Owner * (CASE WHEN NumberRIAFirmAssociations > 1 THEN 1 ELSE 0 END) as Owner_MultiRIA,
        Is_BreakawayRep * (CASE WHEN AUM > 100 THEN 1 ELSE 0 END) as Breakaway_HighAUM,
        
        -- Experience interactions
        (CASE WHEN DateBecameRep_NumberOfYears > 10 THEN 1 ELSE 0 END) * 
        (CASE WHEN AUM > 250 THEN 1 ELSE 0 END) as Veteran_HighAUM,
        
        -- Growth interactions
        (CASE WHEN GrowthRate > 0.15 THEN 1 ELSE 0 END) *
        (CASE WHEN DateBecameRep_NumberOfYears < 5 THEN 1 ELSE 0 END) as NewRep_HighGrowth,
        
        -- === RATIO FEATURES ===
        
        -- Efficiency metrics
        CASE 
            WHEN Number_IAReps > 0 THEN SAFE_DIVIDE(AUM, Number_IAReps)
            ELSE 0
        END as AUM_per_Rep,
        
        -- Tenure ratio
        CASE 
            WHEN DateBecameRep_NumberOfYears > 0 
            THEN SAFE_DIVIDE(DateOfHireAtCurrentFirm_NumberOfYears, DateBecameRep_NumberOfYears)
            ELSE 0
        END as Tenure_Ratio,
        
        -- Client efficiency
        CASE 
            WHEN ClientCount > 0 AND Number_IAReps > 0
            THEN SAFE_DIVIDE(ClientCount, Number_IAReps)
            ELSE 0
        END as Clients_per_Rep,
        
        -- === BINARY FLAGS ===
        
        -- Key thresholds
        CASE WHEN AUM > 100 THEN 1 ELSE 0 END as AUM_Above100M,
        CASE WHEN AUM > 500 THEN 1 ELSE 0 END as AUM_Above500M,
        CASE WHEN ClientCount > 100 THEN 1 ELSE 0 END as Many_Clients,
        CASE WHEN Number_RegisteredStates > 3 THEN 1 ELSE 0 END as Multi_State,
        CASE WHEN DateBecameRep_NumberOfYears > 15 THEN 1 ELSE 0 END as Veteran,
        CASE WHEN GrowthRate > 0.5 THEN 1 ELSE 0 END as High_Growth,
        
        -- Metro indicators (top 10 states by financial activity)
        CASE 
            WHEN Home_State IN ('NY', 'CA', 'TX', 'FL', 'IL', 'MA', 'CT', 'NJ', 'PA', 'GA')
            THEN 1 ELSE 0
        END as Top_Financial_State
        
    FROM cleaned_base
)
SELECT * FROM engineered
"""

print("Extracting enhanced dataset from BigQuery...")
df = client.query(sql_extract_v9).to_dataframe()
print(f"[OK] Loaded {len(df):,} rows")
print(f"  - Positive samples: {df['target_label'].sum():,} ({df['target_label'].mean()*100:.2f}%)")

# ========================================
# STEP 2: INTELLIGENT FEATURE ENGINEERING
# ========================================

print("\n[STEP 2] INTELLIGENT FEATURE ENGINEERING")
print("-"*40)

# Convert categorical features to dummies
categorical_features = ['Career_Stage', 'AUM_Tier', 'Client_Type']
print(f"Encoding {len(categorical_features)} categorical features...")

df_encoded = pd.get_dummies(df, columns=categorical_features, prefix_sep='_', dummy_na=False)

# Create state dummies for top 10 states only
for col in ['Home_State', 'Branch_State']:
    if col in df.columns:
        top_states = df[col].value_counts().head(10).index.tolist()
        for state in top_states[:5]:  # Keep top 5
            df_encoded[f'{col}_{state}'] = (df[col] == state).astype(int)

# Drop original state columns
df_encoded = df_encoded.drop(columns=['Home_State', 'Branch_State'], errors='ignore')

# Define feature groups
id_cols = ['Id', 'FA_CRD__c', 'Stage_Entered_Contacting__c']
target_col = 'target_label'

# Columns to exclude from features
exclude_cols = id_cols + [target_col] + [
    'AssetsInMillions_HNWIndividuals', 'AssetsInMillions_Individuals',
    'NumberClients_HNWIndividuals', 'NumberClients_RetirementPlans',
    'AverageTenureAtPriorFirms', 'NumberOfPriorFirms',
    'total_reps', 'total_firm_aum_millions'
]

# Get feature columns
feature_cols = [col for col in df_encoded.columns if col not in exclude_cols]
print(f"Total features created: {len(feature_cols)}")

# Fill missing values
for col in feature_cols:
    if df_encoded[col].dtype in ['float64', 'int64']:
        df_encoded[col] = df_encoded[col].fillna(0)
    else:
        df_encoded[col] = df_encoded[col].fillna(0)

# ========================================
# STEP 3: SMART FEATURE SELECTION
# ========================================

print("\n[STEP 3] SMART FEATURE SELECTION")
print("-"*40)

# Split data temporally
df_encoded = df_encoded.sort_values('Stage_Entered_Contacting__c')
split_idx = int(len(df_encoded) * 0.8)
train_df = df_encoded.iloc[:split_idx].copy()
test_df = df_encoded.iloc[split_idx:].copy()

X_train_all = train_df[feature_cols].values
y_train = train_df[target_col].values
X_test_all = test_df[feature_cols].values
y_test = test_df[target_col].values

print(f"Train: {len(train_df):,} | Test: {len(test_df):,}")

# Method 1: Random Forest Feature Importance
print("\nMethod 1: Random Forest Feature Importance")
rf_selector = RandomForestClassifier(
    n_estimators=100,
    max_depth=5,
    class_weight='balanced',
    random_state=42,
    n_jobs=-1
)
rf_selector.fit(X_train_all, y_train)

# Get feature importances
rf_importance = pd.DataFrame({
    'feature': feature_cols,
    'importance': rf_selector.feature_importances_
}).sort_values('importance', ascending=False)

# Method 2: XGBoost Feature Importance
print("Method 2: XGBoost Feature Importance")
pos_weight = (y_train == 0).sum() / (y_train == 1).sum() if (y_train == 1).sum() > 0 else 1.0
xgb_selector = xgb.XGBClassifier(
    n_estimators=100,
    max_depth=3,
    scale_pos_weight=pos_weight,
    random_state=42,
    verbosity=0
)
xgb_selector.fit(X_train_all, y_train)

xgb_importance = pd.DataFrame({
    'feature': feature_cols,
    'importance': xgb_selector.feature_importances_
}).sort_values('importance', ascending=False)

# Combine importances (average rank)
print("\nCombining feature importance rankings...")
rf_importance['rf_rank'] = range(1, len(rf_importance) + 1)
xgb_importance['xgb_rank'] = range(1, len(xgb_importance) + 1)

combined_importance = rf_importance.merge(xgb_importance, on='feature', suffixes=('_rf', '_xgb'))
combined_importance['avg_rank'] = (combined_importance['rf_rank'] + combined_importance['xgb_rank']) / 2
combined_importance['combined_importance'] = (combined_importance['importance_rf'] + combined_importance['importance_xgb']) / 2
combined_importance = combined_importance.sort_values('avg_rank')

# Select top features (but ensure m5's proven features are included)
must_have_features = [
    'Multi_RIA', 'HNW_Concentration', 'AUM_per_Client', 'Growth_Momentum',
    'Firm_Stability', 'AUM', 'ClientCount', 'GrowthRate'
]

# Get top 60 features by combined importance
top_features = combined_importance.head(60)['feature'].tolist()

# Ensure must-have features are included
for feature in must_have_features:
    if feature in feature_cols and feature not in top_features:
        top_features.append(feature)
        print(f"  Added must-have feature: {feature}")

selected_features = top_features[:70]  # Cap at 70 features
print(f"\nSelected {len(selected_features)} features")
print(f"Top 10 features:")
for i, feat in enumerate(selected_features[:10], 1):
    imp = combined_importance[combined_importance['feature'] == feat]['combined_importance'].values
    if len(imp) > 0:
        print(f"  {i}. {feat}: {imp[0]:.4f}")

# Prepare final datasets
X_train = train_df[selected_features].values
X_test = test_df[selected_features].values

# ========================================
# STEP 4: ENSEMBLE MODEL TRAINING
# ========================================

print("\n[STEP 4] ENSEMBLE MODEL TRAINING")
print("-"*40)

results = {}

# Model 1: XGBoost with SMOTETomek
print("\n[Model 1] XGBoost with SMOTETomek")
print("-"*30)

# Use SMOTETomek for better class balancing
smote_tomek = SMOTETomek(random_state=42)
X_train_balanced, y_train_balanced = smote_tomek.fit_resample(X_train, y_train)
print(f"  After balancing: {len(X_train_balanced):,} samples ({y_train_balanced.mean()*100:.2f}% positive)")

xgb_params = {
    'max_depth': 4,  # Slightly deeper than V8
    'n_estimators': 300,
    'learning_rate': 0.02,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
    'reg_alpha': 1.0,
    'reg_lambda': 5.0,
    'gamma': 3.0,
    'min_child_weight': 5,
    'objective': 'binary:logistic',
    'eval_metric': 'aucpr',
    'random_state': 42,
    'verbosity': 0
}

xgb_model = xgb.XGBClassifier(**xgb_params)
xgb_model.fit(
    X_train_balanced, 
    y_train_balanced,
    verbose=False
)

xgb_pred = xgb_model.predict_proba(X_test)[:, 1]
xgb_auc_pr = average_precision_score(y_test, xgb_pred)
xgb_auc_roc = roc_auc_score(y_test, xgb_pred)
print(f"  AUC-PR: {xgb_auc_pr:.4f} ({xgb_auc_pr*100:.2f}%)")
print(f"  AUC-ROC: {xgb_auc_roc:.4f}")

results['xgboost'] = {
    'model': xgb_model,
    'predictions': xgb_pred,
    'auc_pr': xgb_auc_pr,
    'auc_roc': xgb_auc_roc
}

# Model 2: Gradient Boosting
print("\n[Model 2] Gradient Boosting")
print("-"*30)

gb_model = GradientBoostingClassifier(
    n_estimators=200,
    max_depth=3,
    learning_rate=0.02,
    subsample=0.8,
    random_state=42
)

# Use original imbalanced data with sample weights
sample_weights = np.ones(len(y_train))
if (y_train == 1).sum() > 0:
    sample_weights[y_train == 1] = (y_train == 0).sum() / (y_train == 1).sum()

gb_model.fit(X_train, y_train, sample_weight=sample_weights)
gb_pred = gb_model.predict_proba(X_test)[:, 1]
gb_auc_pr = average_precision_score(y_test, gb_pred)
gb_auc_roc = roc_auc_score(y_test, gb_pred)
print(f"  AUC-PR: {gb_auc_pr:.4f} ({gb_auc_pr*100:.2f}%)")
print(f"  AUC-ROC: {gb_auc_roc:.4f}")

results['gradient_boosting'] = {
    'model': gb_model,
    'predictions': gb_pred,
    'auc_pr': gb_auc_pr,
    'auc_roc': gb_auc_roc
}

# Model 3: Logistic Regression (calibrated baseline)
print("\n[Model 3] Logistic Regression")
print("-"*30)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_balanced)
X_test_scaled = scaler.transform(X_test)

lr_model = LogisticRegression(
    C=0.01,  # Very strong regularization
    class_weight=None,  # Already balanced
    max_iter=1000,
    random_state=42
)
lr_model.fit(X_train_scaled, y_train_balanced)
lr_pred = lr_model.predict_proba(X_test_scaled)[:, 1]
lr_auc_pr = average_precision_score(y_test, lr_pred)
lr_auc_roc = roc_auc_score(y_test, lr_pred)
print(f"  AUC-PR: {lr_auc_pr:.4f} ({lr_auc_pr*100:.2f}%)")
print(f"  AUC-ROC: {lr_auc_roc:.4f}")

results['logistic'] = {
    'model': lr_model,
    'predictions': lr_pred,
    'auc_pr': lr_auc_pr,
    'auc_roc': lr_auc_roc,
    'scaler': scaler
}

# Model 4: Random Forest
print("\n[Model 4] Random Forest")
print("-"*30)

rf_model = RandomForestClassifier(
    n_estimators=200,
    max_depth=5,
    min_samples_split=20,
    min_samples_leaf=10,
    class_weight='balanced',
    random_state=42,
    n_jobs=-1
)
rf_model.fit(X_train_balanced, y_train_balanced)
rf_pred = rf_model.predict_proba(X_test)[:, 1]
rf_auc_pr = average_precision_score(y_test, rf_pred)
rf_auc_roc = roc_auc_score(y_test, rf_pred)
print(f"  AUC-PR: {rf_auc_pr:.4f} ({rf_auc_pr*100:.2f}%)")
print(f"  AUC-ROC: {rf_auc_roc:.4f}")

results['random_forest'] = {
    'model': rf_model,
    'predictions': rf_pred,
    'auc_pr': rf_auc_pr,
    'auc_roc': rf_auc_roc
}

# ========================================
# STEP 5: ENSEMBLE COMBINATION
# ========================================

print("\n[STEP 5] ENSEMBLE COMBINATION")
print("-"*40)

# Method 1: Simple Average
ensemble_avg = np.mean([results[m]['predictions'] for m in results.keys()], axis=0)
ensemble_avg_auc = average_precision_score(y_test, ensemble_avg)
print(f"Simple Average: {ensemble_avg_auc:.4f} ({ensemble_avg_auc*100:.2f}%)")

# Method 2: Weighted by Performance
weights = np.array([results[m]['auc_pr'] for m in results.keys()])
weights = weights / weights.sum()
ensemble_weighted = np.average(
    [results[m]['predictions'] for m in results.keys()], 
    axis=0, 
    weights=weights
)
ensemble_weighted_auc = average_precision_score(y_test, ensemble_weighted)
print(f"Weighted Average: {ensemble_weighted_auc:.4f} ({ensemble_weighted_auc*100:.2f}%)")

# Method 3: Rank Average
from scipy import stats
rankings = []
for m in results.keys():
    rank = stats.rankdata(results[m]['predictions'])
    rankings.append(rank)
ensemble_rank = np.mean(rankings, axis=0)
ensemble_rank = (ensemble_rank - ensemble_rank.min()) / (ensemble_rank.max() - ensemble_rank.min())
ensemble_rank_auc = average_precision_score(y_test, ensemble_rank)
print(f"Rank Average: {ensemble_rank_auc:.4f} ({ensemble_rank_auc*100:.2f}%)")

# Select best ensemble
best_ensemble_method = 'weighted' if ensemble_weighted_auc >= max(ensemble_avg_auc, ensemble_rank_auc) else \
                      'rank' if ensemble_rank_auc >= ensemble_avg_auc else 'average'
best_ensemble_score = max(ensemble_weighted_auc, ensemble_avg_auc, ensemble_rank_auc)
best_ensemble_pred = ensemble_weighted if best_ensemble_method == 'weighted' else \
                     ensemble_rank if best_ensemble_method == 'rank' else ensemble_avg

print(f"\n[OK] Best Ensemble: {best_ensemble_method.title()} - {best_ensemble_score:.4f} ({best_ensemble_score*100:.2f}%)")

# ========================================
# STEP 6: CROSS-VALIDATION
# ========================================

print("\n[STEP 6] CROSS-VALIDATION")
print("-"*40)

# Use time series split
tscv = TimeSeriesSplit(n_splits=5, test_size=int(len(df_encoded)*0.15))
cv_scores = []
fold_idx = 1

for train_idx, val_idx in tscv.split(df_encoded):
    print(f"\nFold {fold_idx}:")
    
    # Get train/val sets
    X_cv_train = df_encoded.iloc[train_idx][selected_features].values
    y_cv_train = df_encoded.iloc[train_idx][target_col].values
    X_cv_val = df_encoded.iloc[val_idx][selected_features].values
    y_cv_val = df_encoded.iloc[val_idx][target_col].values
    
    # Balance training data
    X_cv_balanced, y_cv_balanced = smote_tomek.fit_resample(X_cv_train, y_cv_train)
    
    # Train XGBoost (usually best single model)
    xgb_cv = xgb.XGBClassifier(**xgb_params)
    xgb_cv.fit(X_cv_balanced, y_cv_balanced, verbose=False)
    
    pred_cv = xgb_cv.predict_proba(X_cv_val)[:, 1]
    auc_pr_cv = average_precision_score(y_cv_val, pred_cv)
    
    cv_scores.append(auc_pr_cv)
    print(f"  AUC-PR: {auc_pr_cv:.4f} ({auc_pr_cv*100:.2f}%)")
    fold_idx += 1

cv_mean = np.mean(cv_scores)
cv_std = np.std(cv_scores)
cv_coef = (cv_std / cv_mean * 100) if cv_mean > 0 else 0

print(f"\nCV Summary:")
print(f"  Mean: {cv_mean:.4f} ({cv_mean*100:.2f}%)")
print(f"  Std: {cv_std:.4f}")
print(f"  CV Coefficient: {cv_coef:.2f}%")

# ========================================
# STEP 7: GENERATE REPORT
# ========================================

print("\n[STEP 7] GENERATING COMPREHENSIVE REPORT")
print("-"*40)

timestamp = datetime.now().strftime("%Y%m%d_%H%M")
report_path = OUTPUT_DIR / f"V9_Model_Report_{timestamp}.md"

# Determine best single model
best_single_model = max(results.keys(), key=lambda x: results[x]['auc_pr'])
best_single_score = results[best_single_model]['auc_pr']

report_content = f"""# V9 Lead Scoring Model Report - Hybrid Intelligence

**Generated:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}  
**Model Version:** V9 Hybrid Intelligence  
**Output Directory:** {OUTPUT_DIR}

---

## Executive Summary

V9 implements a hybrid intelligence approach combining:
- Enhanced feature engineering with {len(selected_features)} carefully selected features
- m5's proven features as core predictors
- Multiple model ensemble for robustness
- Smart class balancing with SMOTETomek

**Performance Achievement:**
- **Best Single Model ({best_single_model}):** {best_single_score:.4f} ({best_single_score*100:.2f}%)
- **Best Ensemble ({best_ensemble_method}):** {best_ensemble_score:.4f} ({best_ensemble_score*100:.2f}%)
- **CV Mean:** {cv_mean:.4f} ({cv_mean*100:.2f}%)
- **CV Stability:** {cv_coef:.2f}%

**Target Achievement:** {"‚úÖ ACHIEVED" if best_ensemble_score > 0.10 else "‚ö†Ô∏è CLOSE" if best_ensemble_score > 0.08 else "‚ùå BELOW"} (Target: 10% AUC-PR)

---

## Model Performance Comparison

| Model | Test AUC-PR | Test AUC-ROC | Rank |
|-------|-------------|--------------|------|
"""

# Add model results
for i, (name, res) in enumerate(sorted(results.items(), key=lambda x: x[1]['auc_pr'], reverse=True), 1):
    report_content += f"| {name.replace('_', ' ').title()} | {res['auc_pr']:.4f} ({res['auc_pr']*100:.2f}%) | {res['auc_roc']:.4f} | #{i} |\n"

report_content += f"""

### Ensemble Performance

| Method | AUC-PR | Improvement |
|--------|--------|-------------|
| Simple Average | {ensemble_avg_auc:.4f} | +{(ensemble_avg_auc - best_single_score)*100:.2f}% |
| Weighted Average | {ensemble_weighted_auc:.4f} | +{(ensemble_weighted_auc - best_single_score)*100:.2f}% |
| Rank Average | {ensemble_rank_auc:.4f} | +{(ensemble_rank_auc - best_single_score)*100:.2f}% |

**Winner:** {best_ensemble_method.title()} Ensemble

---

## Cross-Validation Performance

| Fold | AUC-PR | Status |
|------|--------|--------|"""

for i, score in enumerate(cv_scores, 1):
    status = "‚úÖ" if score > 0.10 else "‚ö†Ô∏è" if score > 0.08 else "‚ùå"
    report_content += f"\n| {i} | {score:.4f} ({score*100:.2f}%) | {status} |"

report_content += f"""

**Summary:**
- Mean: {cv_mean:.4f} ({cv_mean*100:.2f}%)
- Std: {cv_std:.4f}
- CV Coefficient: {cv_coef:.2f}%
- Stability: {"‚úÖ Excellent" if cv_coef < 15 else "‚ö†Ô∏è Good" if cv_coef < 25 else "‚ùå Poor"}

---

## Feature Importance Analysis

### Top 20 Features by Combined Importance

| Rank | Feature | RF Import | XGB Import | Combined |
|------|---------|-----------|------------|----------|"""

for i in range(min(20, len(combined_importance))):
    row = combined_importance.iloc[i]
    report_content += f"\n| {i+1} | {row['feature']} | {row['importance_rf']:.4f} | {row['importance_xgb']:.4f} | {row['combined_importance']:.4f} |"

report_content += f"""

### m5 Core Features Performance

| Feature | Included | Rank | Status |
|---------|----------|------|--------|"""

for feature in must_have_features:
    if feature in selected_features:
        rank = selected_features.index(feature) + 1
        status = "‚úÖ Top 10" if rank <= 10 else "‚ö†Ô∏è Top 30" if rank <= 30 else "‚ùå Low"
        report_content += f"\n| {feature} | Yes | {rank} | {status} |"
    else:
        report_content += f"\n| {feature} | No | N/A | ‚ùå Missing |"

report_content += f"""

---

## Historical Performance Comparison

| Model | Best AUC-PR | CV Mean | CV Stability | Status |
|-------|-------------|---------|--------------|--------|
| V6 | 6.74% | 6.74% | 19.79% | Baseline |
| V7 | 4.98% | 4.98% | 24.75% | Failed |
| V8 | 7.07% | 7.01% | 13.90% | Improved |
| **V9** | **{best_ensemble_score*100:.2f}%** | **{cv_mean*100:.2f}%** | **{cv_coef:.1f}%** | **{"Success!" if best_ensemble_score > 0.10 else "Best Yet"}** |
| m5 (Target) | 14.92% | 14.92% | N/A | Production |

**Progress to m5:** V9 achieves {(best_ensemble_score/0.1492)*100:.1f}% of m5's performance

---

## Production Deployment Recommendation

**Current Recommendation:** {"üöÄ DEPLOY AS PRIMARY" if best_ensemble_score >= 0.10 else "‚ö†Ô∏è DEPLOY AS SECONDARY" if best_ensemble_score >= 0.09 else "‚ùå DO NOT DEPLOY"}

---

**Report Generated:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}  
**Model Version:** V9 Hybrid Intelligence  
**Best Performance:** {best_ensemble_score*100:.2f}% AUC-PR  
**Status:** {"‚úÖ SUCCESS" if best_ensemble_score >= 0.10 else "‚ö†Ô∏è PROMISING" if best_ensemble_score >= 0.09 else "üìä IN PROGRESS"}
"""

# Save report
with open(report_path, 'w', encoding='utf-8') as f:
    f.write(report_content)

print(f"[OK] Report saved to: {report_path}")

# Save model artifacts
print("\nSaving model artifacts...")

# Save ensemble models
ensemble_path = OUTPUT_DIR / f"v9_ensemble_models_{timestamp}.pkl"
with open(ensemble_path, 'wb') as f:
    pickle.dump({
        'models': results,
        'ensemble_method': best_ensemble_method,
        'ensemble_score': best_ensemble_score,
        'selected_features': selected_features
    }, f)
print(f"[OK] Ensemble saved to: {ensemble_path}")

# Save feature list
features_path = OUTPUT_DIR / f"v9_selected_features_{timestamp}.json"
with open(features_path, 'w') as f:
    json.dump(selected_features, f, indent=2)
print(f"[OK] Features saved to: {features_path}")

# Save importance
importance_path = OUTPUT_DIR / f"v9_feature_importance_{timestamp}.csv"
combined_importance.to_csv(importance_path, index=False)
print(f"[OK] Feature importance saved to: {importance_path}")

# Save predictions
predictions_df = pd.DataFrame({
    'Id': test_df['Id'].values,
    'FA_CRD__c': test_df['FA_CRD__c'].values,
    'actual': y_test,
    'ensemble_pred': best_ensemble_pred,
    'xgboost_pred': results['xgboost']['predictions']
})
predictions_path = OUTPUT_DIR / f"v9_predictions_{timestamp}.csv"
predictions_df.to_csv(predictions_path, index=False)
print(f"[OK] Predictions saved to: {predictions_path}")

print("\n" + "="*60)
print("V9 MODEL TRAINING COMPLETE")
print("="*60)
print(f"Best Single Model: {best_single_model} - {best_single_score*100:.2f}%")
print(f"Best Ensemble: {best_ensemble_method} - {best_ensemble_score*100:.2f}%")
print(f"CV Performance: {cv_mean*100:.2f}% ¬± {cv_std*100:.2f}%")
status_text = "ACHIEVED" if best_ensemble_score >= 0.10 else "CLOSE" if best_ensemble_score >= 0.09 else "BELOW"
print(f"Target Status: {status_text}")
print("="*60)

