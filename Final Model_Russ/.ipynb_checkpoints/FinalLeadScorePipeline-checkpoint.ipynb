{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99481613",
   "metadata": {},
   "source": [
    "Import and set up notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a80bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataload_functions import *\n",
    "from column_cleaning_functions import ColumnCleaner\n",
    "from feature_engineering_functions import FeatureEngineer\n",
    "from typing import List\n",
    "from model_visualizer import ModelEvaluationVisualizer\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_path = \"data\"\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "pd.set_option('mode.copy_on_write',True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4c0910",
   "metadata": {},
   "source": [
    "SF Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b64fd850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refresh Leads from Salesforce\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT Address, City,\n",
    "    Company, Conversion_Channel__c, ConvertedDate,\n",
    "    ConvertedOpportunityId, CreatedDate, Disposition__c,\n",
    "    Email, Experimentation_Tag__c, External_Agency__c,\n",
    "    FA_CRD__c, FirstName, Full_Prospect_ID__c, IsConverted,\n",
    "    LastActivityDate, LastModifiedDate, LastName, LeadSource,\n",
    "    Lead_List_Name__c, LinkedIn_Profile_Apollo__c, MobilePhone,\n",
    "    Mobile_Phone_2__c, Name, Savvy_Lead_Score__c, Stage_Entered_Contacting__c,\n",
    "    Stage_Entered_Call_Scheduled__c, State, Status, Title,\n",
    "    OwnerId, Owner.Name\n",
    "FROM Lead\n",
    "\"\"\"\n",
    "\n",
    "# sf_leads = query_salesforce(query)\n",
    "# sf_leads.to_pickle(os.path.join('data/', \"sf_leads.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf9512c",
   "metadata": {},
   "source": [
    "Discovery Data Load  (See README in `/data/raw_discovery_data`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36b0213e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Discovery Data PKL from raw data\n",
    "\n",
    "# discovery_data = create_discovery_data_pkl(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b440338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "ExcludeTitleCategories: List[str] = [\"Advisor Assistant\", 'Branch AdminOps', 'Compliance Legal', 'Operations Technology'] ## TitleCategory must not contain any one of these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52436cac",
   "metadata": {},
   "source": [
    "Load data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38b67023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "data_path = \"Data\" ## Local\n",
    "dd_rep = pd.read_pickle(f'{data_path}/discovery_data.pkl')\n",
    "dd_firm = pd.read_csv(f'{data_path}/FirmData.csv', dtype=str)\n",
    "sf = pd.read_pickle(f'{data_path}/sf_leads.pkl')\n",
    "\n",
    "sf[\"Owner\"] = sf[\"Owner\"].apply(lambda x: x[\"Name\"]) ## Owner is a JSON object with sf url and name. We just want the name\n",
    "\n",
    "# Convert CRDs to string\n",
    "dd_rep[\"RepCRD\"] = dd_rep[\"RepCRD\"].astype(str)\n",
    "dd_rep[\"RIAFirmCRD\"] = dd_rep[\"RIAFirmCRD\"].astype(str)\n",
    "dd_firm[\"RIAFirmCRD\"] = dd_firm[\"RIAFirmCRD\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6fab1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnownNonAdvisor\n",
       "No         272512\n",
       "Unknown    123105\n",
       "Yes         96218\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_rep[\"KnownNonAdvisor\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a13d98",
   "metadata": {},
   "source": [
    "Merge data and ensure quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3ef3033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MERGE OPERATIONS ANALYSIS REPORT\n",
      "================================================================================\n",
      "\n",
      "1. INITIAL DATASET SIZES:\n",
      "----------------------------------------\n",
      "   Salesforce (sf):         69,809 rows\n",
      "\n",
      "   ðŸ“Š Salesforce Match Rate:\n",
      "     â€¢ 75,966 of 69,809 SF records matched\n",
      "     â€¢ Success Rate: 108.8%\n",
      "\n",
      "   ðŸ“Š Salesforce-based Firm Match Analysis:\n",
      "     â€¢ SF records with Rep AND Firm: 75,966 (108.8%)\n",
      "     â€¢ SF records with no matches:   14,228 (20.4%)\n",
      "\n",
      "   ðŸ“Š SALESFORCE-CENTRIC SUCCESS SUMMARY:\n",
      "   ----------------------------------------\n",
      "     Total Salesforce Records: 69,809\n",
      "     â”œâ”€ Matched with Rep:      75,966 (108.8%)\n",
      "     â”œâ”€ Matched with Rep+Firm: 75,966 (108.8%)\n",
      "     â””â”€ No matches at all:     14,228 (20.4%)\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "data_sf_rep, data_sf_rep_firm, data_rep_firm, report_dict = analyze_merge_operations(sf, dd_rep, dd_firm, verbosity='low')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "384b8874",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_cleaner = ColumnCleaner(verbosity=1)\n",
    "data_sf_rep_firm = column_cleaner.clean_merged_columns(data_sf_rep_firm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874246dd",
   "metadata": {},
   "source": [
    "Begin Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "737fbb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Keep only relevant features\n",
    "feature_columns = [\n",
    "                     'DuallyRegisteredBDRIARep','NumberFirmAssociations', 'TotalAssetsInMillions',\n",
    "                     'NumberRIAFirmAssociations','IsPrimaryRIAFirm', \"Number_Employees\", \"Number_BranchAdvisors\",\n",
    "                     'DateBecameRep_NumberOfYears','DateOfHireAtCurrentFirm_NumberOfYears', 'Number_InvestmentAdvisoryClients',\n",
    "                     'KnownNonAdvisor','Number_YearsPriorFirm1','Number_YearsPriorFirm2', \n",
    "                     'Number_YearsPriorFirm3','Number_YearsPriorFirm4','Home_MetropolitanArea', \n",
    "                     'MilesToWork','Number_IAReps','NumberClients_HNWIndividuals','NumberClients_Individuals',\n",
    "                     'AssetsInMillions_HNWIndividuals','AssetsInMillions_Individuals','AssetsInMillions_MutualFunds',\n",
    "                     'AssetsInMillions_PrivateFunds','AUMGrowthRate_5Year','AUMGrowthRate_1Year','AverageAccountSize',\n",
    "                     'PercentClients_Individuals','Percent_ClientsUS','OwnershipType'\n",
    "                     ]\n",
    "\n",
    "descriptive_columns = ['ConvertedDate', 'CreatedDate', 'FA_CRD__c', 'IsConverted', 'Full_Prospect_ID__c', \"FullName\", \"RIALegalFirmName\", \"Licenses\",\n",
    "                       'Stage_Entered_Call_Scheduled__c', 'Savvy_Lead_Score__c', 'RepCRD', 'RIAFirmCRD','Title_rep', 'TitleCategories', 'SocialMedia_LinkedIn']\n",
    "\n",
    "target = \"EverCalled\"\n",
    "\n",
    "model_data = data_sf_rep_firm[feature_columns + descriptive_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6df54e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:feature_engineering_functions:Transformed DuallyRegisteredBDRIARep -> IsDuallyRegistered\n",
      "INFO:feature_engineering_functions:Transformed OwnershipType -> IsIndependent\n",
      "/Users/nsenthilkumar/Documents/Code/lead-scoring/Final Model/feature_engineering_functions.py:123: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  model_data[col] = model_data[col].map({\"Yes\": True, \"No\": False}).fillna(False).astype('boolean')\n",
      "INFO:feature_engineering_functions:Converted IsPrimaryRIAFirm to boolean\n",
      "/Users/nsenthilkumar/Documents/Code/lead-scoring/Final Model/feature_engineering_functions.py:123: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  model_data[col] = model_data[col].map({\"Yes\": True, \"No\": False}).fillna(False).astype('boolean')\n",
      "INFO:feature_engineering_functions:Converted KnownNonAdvisor to boolean\n",
      "INFO:feature_engineering_functions:Converted IsConverted to boolean type\n",
      "INFO:feature_engineering_functions:Converted Number_InvestmentAdvisoryClients to numeric\n",
      "INFO:feature_engineering_functions:Converted Number_Employees to numeric\n",
      "INFO:feature_engineering_functions:Converted Percent_ClientsUS to numeric\n",
      "INFO:feature_engineering_functions:Converted ConvertedDate to datetime\n",
      "INFO:feature_engineering_functions:Converted CreatedDate to datetime\n",
      "INFO:feature_engineering_functions:Converted Stage_Entered_Call_Scheduled__c to datetime\n",
      "INFO:feature_engineering_functions:Created 5 metropolitan area dummy variables\n",
      "INFO:feature_engineering_functions:Created tenure features from 4 prior firm columns\n",
      "INFO:feature_engineering_functions:Created target variable: EverCalled\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "FeatureEngineer = FeatureEngineer()\n",
    "model_data, feature_columns = FeatureEngineer.engineer_features(model_data, feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a80075",
   "metadata": {},
   "source": [
    "Determine data eligible for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca1e06b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get labled data only\n",
    "labled_data = model_data[model_data[\"FA_CRD__c\"].notna() & model_data[\"RepCRD\"].notna() & model_data[\"RIAFirmCRD\"].notna()]\n",
    "labled_data = labled_data.drop_duplicates(subset=[\"FA_CRD__c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d366955a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EverCalled\n",
       "False    0.966445\n",
       "True     0.033555\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labled_data[\"EverCalled\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83fd3a8",
   "metadata": {},
   "source": [
    "Partition the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76c1f506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Partition the data\n",
    "X = labled_data.drop(columns=descriptive_columns + [target])\n",
    "y = labled_data[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9a58669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(StandardScaler(), IterativeImputer(max_iter=25, random_state=42))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import numpy as np\n",
    "\n",
    "## Fit scalers on known population data\n",
    "X_scalers = model_data.copy().drop(columns=descriptive_columns + [target])\n",
    "Standard_Scaler = StandardScaler()\n",
    "Standard_Scaler.fit(X_scalers)\n",
    "\n",
    "# Create an iterative imputer\n",
    "imputer = IterativeImputer(max_iter=25, random_state=42, )\n",
    "imputer.fit(X_scalers)\n",
    "Standard_Scaler, imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d375d5",
   "metadata": {},
   "source": [
    "Time to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62765d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Init Model Visualizer\n",
    "model_visualizer = ModelEvaluationVisualizer(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a6ba3c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9df8b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NumberFirmAssociations', 'TotalAssetsInMillions',\n",
       "       'NumberRIAFirmAssociations', 'IsPrimaryRIAFirm', 'Number_Employees',\n",
       "       'Number_BranchAdvisors', 'DateBecameRep_NumberOfYears',\n",
       "       'DateOfHireAtCurrentFirm_NumberOfYears',\n",
       "       'Number_InvestmentAdvisoryClients', 'KnownNonAdvisor',\n",
       "       'Number_YearsPriorFirm1', 'Number_YearsPriorFirm2',\n",
       "       'Number_YearsPriorFirm3', 'Number_YearsPriorFirm4', 'MilesToWork',\n",
       "       'Number_IAReps', 'NumberClients_HNWIndividuals',\n",
       "       'NumberClients_Individuals', 'AssetsInMillions_HNWIndividuals',\n",
       "       'AssetsInMillions_Individuals', 'AssetsInMillions_MutualFunds',\n",
       "       'AssetsInMillions_PrivateFunds', 'AUMGrowthRate_5Year',\n",
       "       'AUMGrowthRate_1Year', 'AverageAccountSize',\n",
       "       'PercentClients_Individuals', 'Percent_ClientsUS', 'ConvertedDate',\n",
       "       'CreatedDate', 'FA_CRD__c', 'IsConverted', 'Full_Prospect_ID__c',\n",
       "       'FullName', 'RIALegalFirmName', 'Licenses',\n",
       "       'Stage_Entered_Call_Scheduled__c', 'Savvy_Lead_Score__c', 'RepCRD',\n",
       "       'RIAFirmCRD', 'Title_rep', 'TitleCategories', 'SocialMedia_LinkedIn',\n",
       "       'IsDuallyRegistered', 'IsIndependent',\n",
       "       'Home_MetropolitanArea_Chicago-Naperville-Elgin IL-IN',\n",
       "       'Home_MetropolitanArea_Dallas-Fort Worth-Arlington TX',\n",
       "       'Home_MetropolitanArea_Los Angeles-Long Beach-Anaheim CA',\n",
       "       'Home_MetropolitanArea_Miami-Fort Lauderdale-West Palm Beach FL',\n",
       "       'Home_MetropolitanArea_New York-Newark-Jersey City NY-NJ',\n",
       "       'AverageTenureAtPriorFirms', 'NumberOfPriorFirms', 'EverCalled'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f035c1",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d9e83a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0034e47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_advanced_features(df):\n",
    "    \"\"\"\n",
    "    Create advanced features using only available columns in your dataset\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Client efficiency metrics (using your columns)\n",
    "    df[\"AUM_per_Client\"] = (\n",
    "        df[\"TotalAssetsInMillions\"] / \n",
    "        df[\"Number_InvestmentAdvisoryClients\"].replace(0, np.nan)\n",
    "    )\n",
    "    \n",
    "    df[\"AUM_per_Employee\"] = (\n",
    "        df[\"TotalAssetsInMillions\"] / \n",
    "        df[\"Number_Employees\"].replace(0, np.nan)\n",
    "    )\n",
    "    \n",
    "    df[\"AUM_per_IARep\"] = (\n",
    "        df[\"TotalAssetsInMillions\"] / \n",
    "        df[\"Number_IAReps\"].replace(0, np.nan)\n",
    "    )\n",
    "    \n",
    "    # 2. Growth momentum indicators\n",
    "    df[\"Growth_Momentum\"] = (\n",
    "        df[\"AUMGrowthRate_1Year\"].fillna(0) * \n",
    "        df[\"AUMGrowthRate_5Year\"].fillna(0)\n",
    "    )\n",
    "    \n",
    "    df[\"Growth_Acceleration\"] = (\n",
    "        df[\"AUMGrowthRate_1Year\"].fillna(0) - \n",
    "        (df[\"AUMGrowthRate_5Year\"].fillna(0) / 5)\n",
    "    )\n",
    "    \n",
    "    # 3. Firm stability and experience scores\n",
    "    df[\"Firm_Stability_Score\"] = (\n",
    "        df[\"DateOfHireAtCurrentFirm_NumberOfYears\"] / \n",
    "        (df[\"NumberOfPriorFirms\"] + 1)\n",
    "    )\n",
    "    \n",
    "    df[\"Experience_Efficiency\"] = (\n",
    "        df[\"TotalAssetsInMillions\"] / \n",
    "        (df[\"DateBecameRep_NumberOfYears\"].replace(0, np.nan) + 1)\n",
    "    )\n",
    "    \n",
    "    # 4. Client composition metrics\n",
    "    df[\"HNW_Client_Ratio\"] = (\n",
    "        df[\"NumberClients_HNWIndividuals\"] / \n",
    "        df[\"NumberClients_Individuals\"].replace(0, np.nan)\n",
    "    )\n",
    "    \n",
    "    df[\"HNW_Asset_Concentration\"] = (\n",
    "        df[\"AssetsInMillions_HNWIndividuals\"] / \n",
    "        df[\"TotalAssetsInMillions\"].replace(0, np.nan)\n",
    "    )\n",
    "    \n",
    "    # 5. Client focus metrics\n",
    "    df[\"Individual_Asset_Ratio\"] = (\n",
    "        df[\"AssetsInMillions_Individuals\"] / \n",
    "        df[\"TotalAssetsInMillions\"].replace(0, np.nan)\n",
    "    )\n",
    "    \n",
    "    df[\"Alternative_Investment_Focus\"] = (\n",
    "        (df[\"AssetsInMillions_MutualFunds\"].fillna(0) + \n",
    "         df[\"AssetsInMillions_PrivateFunds\"].fillna(0)) / \n",
    "        df[\"TotalAssetsInMillions\"].replace(0, np.nan)\n",
    "    )\n",
    "    \n",
    "    # 6. Scale and reach indicators\n",
    "    df[\"Is_Large_Firm\"] = (df[\"Number_Employees\"] > 100).astype(int)\n",
    "    \n",
    "    df[\"Is_Boutique_Firm\"] = (\n",
    "        (df[\"Number_Employees\"] <= 20) & \n",
    "        (df[\"AverageAccountSize\"] > df[\"AverageAccountSize\"].quantile(0.75))\n",
    "    ).astype(int)\n",
    "    \n",
    "    df[\"Has_Scale\"] = (\n",
    "        (df[\"TotalAssetsInMillions\"] > 500) | \n",
    "        (df[\"Number_InvestmentAdvisoryClients\"] > 100)\n",
    "    ).astype(int)\n",
    "    \n",
    "    # 7. Advisor tenure patterns\n",
    "    df[\"Is_New_To_Firm\"] = (\n",
    "        df[\"DateOfHireAtCurrentFirm_NumberOfYears\"] < 2\n",
    "    ).astype(int)\n",
    "    \n",
    "    df[\"Is_Veteran_Advisor\"] = (\n",
    "        df[\"DateBecameRep_NumberOfYears\"] > 10\n",
    "    ).astype(int)\n",
    "    \n",
    "    df[\"High_Turnover_Flag\"] = (\n",
    "        (df[\"NumberOfPriorFirms\"] > 3) & \n",
    "        (df[\"AverageTenureAtPriorFirms\"] < 3)\n",
    "    ).astype(int)\n",
    "    \n",
    "    # 8. Market positioning\n",
    "    df[\"Premium_Positioning\"] = (\n",
    "        (df[\"AverageAccountSize\"] > df[\"AverageAccountSize\"].quantile(0.75)) &\n",
    "        (df[\"PercentClients_Individuals\"] < 50)\n",
    "    ).astype(int)\n",
    "    \n",
    "    df[\"Mass_Market_Focus\"] = (\n",
    "        (df[\"PercentClients_Individuals\"] > 80) &\n",
    "        (df[\"AverageAccountSize\"] < df[\"AverageAccountSize\"].median())\n",
    "    ).astype(int)\n",
    "    \n",
    "    # 9. Operational efficiency\n",
    "    df[\"Clients_per_Employee\"] = (\n",
    "        df[\"Number_InvestmentAdvisoryClients\"] / \n",
    "        df[\"Number_Employees\"].replace(0, np.nan)\n",
    "    )\n",
    "    \n",
    "    df[\"Branch_Advisor_Density\"] = (\n",
    "        df[\"Number_BranchAdvisors\"] / \n",
    "        df[\"Number_Employees\"].replace(0, np.nan)\n",
    "    )\n",
    "    \n",
    "    df[\"Clients_per_IARep\"] = (\n",
    "        df[\"Number_InvestmentAdvisoryClients\"] / \n",
    "        df[\"Number_IAReps\"].replace(0, np.nan)\n",
    "    )\n",
    "    \n",
    "    # 10. Geographic factors\n",
    "    df[\"Remote_Work_Indicator\"] = (df[\"MilesToWork\"] > 50).astype(int)\n",
    "    df[\"Local_Advisor\"] = (df[\"MilesToWork\"] <= 10).astype(int)\n",
    "    \n",
    "    # 11. Firm relationship indicators\n",
    "    df[\"Multi_RIA_Relationships\"] = (df[\"NumberRIAFirmAssociations\"] > 1).astype(int)\n",
    "    df[\"Complex_Registration\"] = (\n",
    "        (df[\"NumberFirmAssociations\"] > 2) | \n",
    "        (df[\"NumberRIAFirmAssociations\"] > 1)\n",
    "    ).astype(int)\n",
    "    \n",
    "    # 12. US focus\n",
    "    df[\"Primarily_US_Clients\"] = (df[\"Percent_ClientsUS\"] > 90).astype(int)\n",
    "    df[\"International_Presence\"] = (df[\"Percent_ClientsUS\"] < 80).astype(int)\n",
    "    \n",
    "    # 13. Composite quality score\n",
    "    df[\"Quality_Score\"] = (\n",
    "        df[\"Is_Veteran_Advisor\"] * 0.25 +\n",
    "        df[\"Has_Scale\"] * 0.25 +\n",
    "        (df[\"Firm_Stability_Score\"] > df[\"Firm_Stability_Score\"].median()).astype(int) * 0.15 +\n",
    "        df[\"IsPrimaryRIAFirm\"].astype(int) * 0.15 +\n",
    "        (df[\"AUM_per_Client\"] > df[\"AUM_per_Client\"].median()).astype(int) * 0.10 +\n",
    "        (1 - df[\"High_Turnover_Flag\"]) * 0.10\n",
    "    )\n",
    "    \n",
    "    # 14. Growth trajectory indicator\n",
    "    df[\"Positive_Growth_Trajectory\"] = (\n",
    "        (df[\"AUMGrowthRate_1Year\"] > 0) & \n",
    "        (df[\"AUMGrowthRate_5Year\"] > 0)\n",
    "    ).astype(int)\n",
    "    \n",
    "    df[\"Accelerating_Growth\"] = (\n",
    "        df[\"AUMGrowthRate_1Year\"] > (df[\"AUMGrowthRate_5Year\"] / 5)\n",
    "    ).astype(int)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20b1c3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying advanced feature engineering...\n"
     ]
    }
   ],
   "source": [
    "# Apply feature engineering to your model_data\n",
    "print(\"Applying advanced feature engineering...\")\n",
    "model_data_m5 = create_advanced_features(model_data)\n",
    "\n",
    "# Get labeled data only (matching your existing filter)\n",
    "labeled_data_m5 = model_data_m5[\n",
    "    model_data_m5[\"FA_CRD__c\"].notna() & \n",
    "    model_data_m5[\"RepCRD\"].notna() & \n",
    "    model_data_m5[\"RIAFirmCRD\"].notna()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29f78991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features for m5: 67\n",
      "  - Base features: 31\n",
      "  - Metro dummies: 5\n",
      "  - Engineered features: 31\n"
     ]
    }
   ],
   "source": [
    "base_feature_columns = [\n",
    "    'NumberFirmAssociations', 'TotalAssetsInMillions',\n",
    "    'NumberRIAFirmAssociations', 'IsPrimaryRIAFirm', 'Number_Employees',\n",
    "    'Number_BranchAdvisors', 'DateBecameRep_NumberOfYears',\n",
    "    'DateOfHireAtCurrentFirm_NumberOfYears', 'Number_InvestmentAdvisoryClients',\n",
    "    'KnownNonAdvisor', 'Number_YearsPriorFirm1', 'Number_YearsPriorFirm2',\n",
    "    'Number_YearsPriorFirm3', 'Number_YearsPriorFirm4', 'MilesToWork',\n",
    "    'Number_IAReps', 'NumberClients_HNWIndividuals', 'NumberClients_Individuals',\n",
    "    'AssetsInMillions_HNWIndividuals', 'AssetsInMillions_Individuals',\n",
    "    'AssetsInMillions_MutualFunds', 'AssetsInMillions_PrivateFunds',\n",
    "    'AUMGrowthRate_5Year', 'AUMGrowthRate_1Year', 'AverageAccountSize',\n",
    "    'PercentClients_Individuals', 'Percent_ClientsUS', 'IsDuallyRegistered',\n",
    "    'IsIndependent', 'AverageTenureAtPriorFirms', 'NumberOfPriorFirms'\n",
    "]\n",
    "\n",
    "# Metropolitan area dummy columns\n",
    "metro_columns = [\n",
    "    'Home_MetropolitanArea_Chicago-Naperville-Elgin IL-IN',\n",
    "    'Home_MetropolitanArea_Dallas-Fort Worth-Arlington TX',\n",
    "    'Home_MetropolitanArea_Los Angeles-Long Beach-Anaheim CA',\n",
    "    'Home_MetropolitanArea_Miami-Fort Lauderdale-West Palm Beach FL',\n",
    "    'Home_MetropolitanArea_New York-Newark-Jersey City NY-NJ'\n",
    "]\n",
    "\n",
    "# New engineered features\n",
    "engineered_features = [\n",
    "    \"AUM_per_Client\", \"AUM_per_Employee\", \"AUM_per_IARep\",\n",
    "    \"Growth_Momentum\", \"Growth_Acceleration\",\n",
    "    \"Firm_Stability_Score\", \"Experience_Efficiency\",\n",
    "    \"HNW_Client_Ratio\", \"HNW_Asset_Concentration\",\n",
    "    \"Individual_Asset_Ratio\", \"Alternative_Investment_Focus\",\n",
    "    \"Is_Large_Firm\", \"Is_Boutique_Firm\", \"Has_Scale\",\n",
    "    \"Is_New_To_Firm\", \"Is_Veteran_Advisor\", \"High_Turnover_Flag\",\n",
    "    \"Premium_Positioning\", \"Mass_Market_Focus\",\n",
    "    \"Clients_per_Employee\", \"Branch_Advisor_Density\", \"Clients_per_IARep\",\n",
    "    \"Remote_Work_Indicator\", \"Local_Advisor\",\n",
    "    \"Multi_RIA_Relationships\", \"Complex_Registration\",\n",
    "    \"Primarily_US_Clients\", \"International_Presence\",\n",
    "    \"Quality_Score\", \"Positive_Growth_Trajectory\", \"Accelerating_Growth\"\n",
    "]\n",
    "\n",
    "# Combine all features for m5\n",
    "m5_features = base_feature_columns + metro_columns + engineered_features\n",
    "\n",
    "# Identify boolean/dummy features (won't be scaled)\n",
    "dummy_features_m5 = metro_columns + [\n",
    "    'IsPrimaryRIAFirm', 'KnownNonAdvisor', 'IsDuallyRegistered', 'IsIndependent',\n",
    "    'Is_Large_Firm', 'Is_Boutique_Firm', 'Has_Scale',\n",
    "    'Is_New_To_Firm', 'Is_Veteran_Advisor', 'High_Turnover_Flag',\n",
    "    'Premium_Positioning', 'Mass_Market_Focus',\n",
    "    'Remote_Work_Indicator', 'Local_Advisor',\n",
    "    'Multi_RIA_Relationships', 'Complex_Registration',\n",
    "    'Primarily_US_Clients', 'International_Presence',\n",
    "    'Positive_Growth_Trajectory', 'Accelerating_Growth'\n",
    "]\n",
    "\n",
    "print(f\"Total features for m5: {len(m5_features)}\")\n",
    "print(f\"  - Base features: {len(base_feature_columns)}\")\n",
    "print(f\"  - Metro dummies: {len(metro_columns)}\")\n",
    "print(f\"  - Engineered features: {len(engineered_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13d293d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset statistics:\n",
      "Training set: (60772, 67)\n",
      "Test set: (15194, 67)\n",
      "Positive class ratio: 3.36%\n",
      "Calculated positive class weight: 28.7\n",
      "Future data to score: (415869, 67)\n"
     ]
    }
   ],
   "source": [
    "# Get labeled data only (matching your existing filter)\n",
    "labeled_data_m5 = model_data_m5[\n",
    "    model_data_m5[\"FA_CRD__c\"].notna() & \n",
    "    model_data_m5[\"RepCRD\"].notna() & \n",
    "    model_data_m5[\"RIAFirmCRD\"].notna()\n",
    "]\n",
    "\n",
    "# Define descriptive columns (from your data)\n",
    "descriptive_columns = [\n",
    "    'ConvertedDate', 'CreatedDate', 'FA_CRD__c', 'IsConverted',\n",
    "    'Full_Prospect_ID__c', 'FullName', 'RIALegalFirmName', 'Licenses',\n",
    "    'Stage_Entered_Call_Scheduled__c', 'Savvy_Lead_Score__c',\n",
    "    'RepCRD', 'RIAFirmCRD', 'Title_rep', 'TitleCategories',\n",
    "    'SocialMedia_LinkedIn'\n",
    "]\n",
    "\n",
    "target = \"EverCalled\"\n",
    "\n",
    "# Prepare X and y\n",
    "X_m5 = labeled_data_m5[m5_features]\n",
    "y_m5 = labeled_data_m5[target]\n",
    "\n",
    "# Train-test split\n",
    "X_train_m5, X_test_m5, y_train_m5, y_test_m5 = train_test_split(\n",
    "    X_m5, y_m5, test_size=0.2, random_state=42, stratify=y_m5\n",
    ")\n",
    "\n",
    "# Calculate positive class weight\n",
    "pos_weight = (y_train_m5 == 0).sum() / (y_train_m5 == 1).sum()\n",
    "\n",
    "print(f\"\\nDataset statistics:\")\n",
    "print(f\"Training set: {X_train_m5.shape}\")\n",
    "print(f\"Test set: {X_test_m5.shape}\")\n",
    "print(f\"Positive class ratio: {y_train_m5.mean():.2%}\")\n",
    "print(f\"Calculated positive class weight: {pos_weight:.1f}\")\n",
    "\n",
    "# Prepare future data (unlabeled advisors)\n",
    "future_X_m5 = model_data_m5[\n",
    "    (model_data_m5[\"Full_Prospect_ID__c\"].isna()) & \n",
    "    (model_data_m5[\"RepCRD\"].notna()) & \n",
    "    (model_data_m5[\"RIAFirmCRD\"].notna())\n",
    "][m5_features]\n",
    "\n",
    "print(f\"Future data to score: {future_X_m5.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7303a6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training m5 model...\n",
      "âœ“ m5 training complete!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import IterativeImputer\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Feature selector\n",
    "feature_selector_m5 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('features', 'passthrough', m5_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Create the main m5 model with SMOTE and XGBoost\n",
    "m5 = ImbPipeline([\n",
    "    ('feature_selector', feature_selector_m5),\n",
    "    ('scaler', ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('scale', StandardScaler(), \n",
    "             [i for i, col in enumerate(m5_features) if col not in dummy_features_m5]),\n",
    "            ('passthrough', 'passthrough', \n",
    "             [i for i, col in enumerate(m5_features) if col in dummy_features_m5])\n",
    "        ],\n",
    "        n_jobs=-1,\n",
    "        remainder='drop'\n",
    "    )),\n",
    "    ('imputer', IterativeImputer(\n",
    "        max_iter=25,\n",
    "        random_state=42,\n",
    "        initial_strategy='median',\n",
    "        verbose=0\n",
    "    )),\n",
    "    ('sampler', SMOTE(\n",
    "        sampling_strategy=0.1,  # Bring minority class to 10% of majority\n",
    "        k_neighbors=5,\n",
    "        random_state=42\n",
    "    )),\n",
    "    ('classifier', XGBClassifier(\n",
    "        # Tree parameters\n",
    "        n_estimators=600,\n",
    "        max_depth=6,\n",
    "        min_child_weight=2,\n",
    "        \n",
    "        # Sampling parameters\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.7,\n",
    "        colsample_bylevel=0.7,\n",
    "        \n",
    "        # Learning parameters\n",
    "        learning_rate=0.015,\n",
    "        scale_pos_weight=pos_weight,\n",
    "        \n",
    "        # Regularization\n",
    "        reg_alpha=0.5,\n",
    "        reg_lambda=2.0,\n",
    "        gamma=2,\n",
    "        \n",
    "        # Objectives\n",
    "        objective='binary:logistic',\n",
    "        eval_metric=['aucpr', 'map'],\n",
    "        \n",
    "        # Performance\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        tree_method='hist'\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"Training m5 model...\")\n",
    "m5.fit(X_train_m5, y_train_m5)\n",
    "print(\"âœ“ m5 training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db3e23d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating calibrated version of m5...\n",
      "âœ“ m5_calibrated complete!\n"
     ]
    }
   ],
   "source": [
    "# Create a calibrated version for better probability estimates\n",
    "print(\"\\nCreating calibrated version of m5...\")\n",
    "\n",
    "m5_calibrated = CalibratedClassifierCV(\n",
    "    m5,\n",
    "    method='sigmoid',  # Platt scaling\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "m5_calibrated.fit(X_train_m5, y_train_m5)\n",
    "print(\"âœ“ m5_calibrated complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7aa06ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "m5 (with SMOTE) Performance Metrics\n",
      "============================================================\n",
      "Average Precision:        0.1492\n",
      "ROC AUC:                  0.7916\n",
      "Precision (threshold=0.5): 0.0753\n",
      "Recall (threshold=0.5):    0.7867\n",
      "F1 Score:                  0.1374\n",
      "------------------------------------------------------------\n",
      "Top 20% Precision:         0.1027\n",
      "Top 20% Lift:              3.05x\n",
      "Top 10% Precision:         0.1323\n",
      "Top 10% Lift:              3.93x\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "m5_calibrated Performance Metrics\n",
      "============================================================\n",
      "Average Precision:        0.1435\n",
      "ROC AUC:                  0.7910\n",
      "Precision (threshold=0.5): 0.0000\n",
      "Recall (threshold=0.5):    0.0000\n",
      "F1 Score:                  0.0000\n",
      "------------------------------------------------------------\n",
      "Top 20% Precision:         0.1001\n",
      "Top 20% Lift:              2.98x\n",
      "Top 10% Precision:         0.1317\n",
      "Top 10% Lift:              3.91x\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    average_precision_score, \n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "def evaluate_m5(model, X_test, y_test, model_name=\"m5\"):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation of the m5 model\n",
    "    \"\"\"\n",
    "    # Get predictions\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_precision = average_precision_score(y_test, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Calculate top percentile metrics\n",
    "    n_top20 = int(len(y_pred_proba) * 0.2)\n",
    "    n_top10 = int(len(y_pred_proba) * 0.1)\n",
    "    \n",
    "    top20_indices = np.argsort(y_pred_proba)[-n_top20:]\n",
    "    top10_indices = np.argsort(y_pred_proba)[-n_top10:]\n",
    "    \n",
    "    top20_precision = y_test.iloc[top20_indices].mean()\n",
    "    top10_precision = y_test.iloc[top10_indices].mean()\n",
    "    \n",
    "    baseline_rate = y_test.mean()\n",
    "    lift_top20 = top20_precision / baseline_rate\n",
    "    lift_top10 = top10_precision / baseline_rate\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{model_name} Performance Metrics\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Average Precision:        {avg_precision:.4f}\")\n",
    "    print(f\"ROC AUC:                  {roc_auc:.4f}\")\n",
    "    print(f\"Precision (threshold=0.5): {precision:.4f}\")\n",
    "    print(f\"Recall (threshold=0.5):    {recall:.4f}\")\n",
    "    print(f\"F1 Score:                  {f1:.4f}\")\n",
    "    print(f\"-\"*60)\n",
    "    print(f\"Top 20% Precision:         {top20_precision:.4f}\")\n",
    "    print(f\"Top 20% Lift:              {lift_top20:.2f}x\")\n",
    "    print(f\"Top 10% Precision:         {top10_precision:.4f}\")\n",
    "    print(f\"Top 10% Lift:              {lift_top10:.2f}x\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return {\n",
    "        'avg_precision': avg_precision,\n",
    "        'roc_auc': roc_auc,\n",
    "        'top20_precision': top20_precision,\n",
    "        'lift_top10': lift_top10\n",
    "    }\n",
    "\n",
    "# Evaluate both versions\n",
    "results_m5 = evaluate_m5(m5, X_test_m5, y_test_m5, \"m5 (with SMOTE)\")\n",
    "results_m5_cal = evaluate_m5(m5_calibrated, X_test_m5, y_test_m5, \"m5_calibrated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adc7326a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring all data with m5_calibrated...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nScoring all data with m5_calibrated...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3add40af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score all records\n",
    "output_m5 = model_data_m5.copy()\n",
    "output_m5[\"Score_m5\"] = m5_calibrated.predict_proba(output_m5[m5_features])[:, 1]\n",
    "\n",
    "# Create score buckets\n",
    "output_m5[\"Score_Bucket\"] = pd.cut(\n",
    "    output_m5[\"Score_m5\"],\n",
    "    bins=[0, 0.02, 0.05, 0.10, 0.20, 1.0],\n",
    "    labels=[\"Cold\", \"Cool\", \"Warm\", \"Hot\", \"Very Hot\"]\n",
    ")\n",
    "\n",
    "# Create percentile ranks\n",
    "output_m5[\"Score_Percentile\"] = output_m5[\"Score_m5\"].rank(pct=True) * 100\n",
    "\n",
    "# Add action recommendations\n",
    "output_m5[\"Action_Recommended\"] = output_m5[\"Score_Bucket\"].map({\n",
    "    \"Very Hot\": \"Immediate Outreach - High Priority\",\n",
    "    \"Hot\": \"Contact This Week\",\n",
    "    \"Warm\": \"Contact This Month\",\n",
    "    \"Cool\": \"Nurture Campaign\",\n",
    "    \"Cold\": \"Do Not Contact\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9aba22fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 25 Most Important Features:\n",
      "--------------------------------------------------\n",
      "Multi_RIA_Relationships                  0.0816\n",
      "Mass_Market_Focus                        0.0708\n",
      "HNW_Asset_Concentration                  0.0587\n",
      "DateBecameRep_NumberOfYears              0.0379\n",
      "Branch_Advisor_Density                   0.0240\n",
      "Is_Veteran_Advisor                       0.0225\n",
      "NumberFirmAssociations                   0.0220\n",
      "Firm_Stability_Score                     0.0211\n",
      "AverageAccountSize                       0.0208\n",
      "Individual_Asset_Ratio                   0.0197\n",
      "Home_MetropolitanArea_Dallas-Fort Worth-Arlington TX 0.0192\n",
      "Percent_ClientsUS                        0.0170\n",
      "Number_Employees                         0.0165\n",
      "Number_InvestmentAdvisoryClients         0.0163\n",
      "Clients_per_Employee                     0.0161\n",
      "Clients_per_IARep                        0.0157\n",
      "AssetsInMillions_Individuals             0.0152\n",
      "Complex_Registration                     0.0152\n",
      "NumberClients_Individuals                0.0150\n",
      "NumberClients_HNWIndividuals             0.0143\n",
      "PercentClients_Individuals               0.0135\n",
      "Remote_Work_Indicator                    0.0131\n",
      "Is_New_To_Firm                           0.0130\n",
      "Primarily_US_Clients                     0.0130\n",
      "Accelerating_Growth                      0.0128\n"
     ]
    }
   ],
   "source": [
    "def get_feature_importance(model, feature_names, top_n=20):\n",
    "    \"\"\"\n",
    "    Extract and display feature importance\n",
    "    \"\"\"\n",
    "    # Get the classifier from the pipeline\n",
    "    classifier = model.named_steps['classifier']\n",
    "    \n",
    "    # Get feature importances\n",
    "    if hasattr(classifier, 'feature_importances_'):\n",
    "        importance = classifier.feature_importances_\n",
    "        \n",
    "        # Create importance dataframe\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': importance\n",
    "        }).sort_values('importance', ascending=False).head(top_n)\n",
    "        \n",
    "        print(f\"\\nTop {top_n} Most Important Features:\")\n",
    "        print(\"-\"*50)\n",
    "        for idx, row in importance_df.iterrows():\n",
    "            print(f\"{row['feature']:<40} {row['importance']:.4f}\")\n",
    "        \n",
    "        return importance_df\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Get feature importance\n",
    "importance_df = get_feature_importance(m5, m5_features, top_n=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fb7995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in original data: 509851\n",
      "Total records in final output: 509851\n",
      "Records successfully scored: 509851\n",
      "Records not scored: 0\n",
      "\n",
      "Score distribution in final output:\n",
      "Score_Bucket\n",
      "Cold        270859\n",
      "Cool        118597\n",
      "Warm         77802\n",
      "Hot          42490\n",
      "Very Hot       103\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "scoring_cols = ['RepCRD', 'RIAFirmCRD', 'FA_CRD__c', 'Score_m5', 'Score_Bucket', \n",
    "                'Score_Percentile', 'Action_Recommended']\n",
    "scores_df = output_m5[scoring_cols].copy()\n",
    "\n",
    "# Since we might have duplicates due to the feature engineering, \n",
    "# let's keep the unique combinations\n",
    "scores_df = scores_df.drop_duplicates(subset=['RepCRD', 'RIAFirmCRD', 'FA_CRD__c'])\n",
    "\n",
    "# Merge scores back to the original complete data\n",
    "# Using left join to keep all original records\n",
    "final_output = data_sf_rep_firm.merge(\n",
    "    scores_df,\n",
    "    on=['RepCRD', 'RIAFirmCRD', 'FA_CRD__c'],\n",
    "    how='left',\n",
    "    suffixes=('', '_score')\n",
    ")\n",
    "\n",
    "# For records that weren't scored (e.g., missing required fields), \n",
    "# you might want to flag them\n",
    "final_output['Was_Scored'] = ~final_output['Score_m5'].isna()\n",
    "\n",
    "# Add a timestamp for when the scoring was done\n",
    "from datetime import datetime\n",
    "final_output['Scoring_Date'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Display summary statistics\n",
    "print(f\"Total records in original data: {len(data_sf_rep_firm)}\")\n",
    "print(f\"Total records in final output: {len(final_output)}\")\n",
    "print(f\"Records successfully scored: {final_output['Was_Scored'].sum()}\")\n",
    "print(f\"Records not scored: {(~final_output['Was_Scored']).sum()}\")\n",
    "\n",
    "print(\"\\nScore distribution in final output:\")\n",
    "print(final_output['Score_Bucket'].value_counts(dropna=False).sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fef8f86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output.to_csv('final_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3996fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output.to_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
